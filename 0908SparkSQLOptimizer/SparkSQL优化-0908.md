SparkSQL优化作业

目录： 

## 题目1 

如何避免小文件问题 

其实没有完美的解决办法，最终思路还是于小文件大小个数和写入速度上的一个trade off

### 思路1 ： 减少reduce个数

在不影响作业运行的并行度情况下，尽量去减少reduce个数。

1. spark中repartition和coalesce就是通过减少分区数来避免过多小文件输出。
2. spark AQE根据shuffle write数据量动态调整reduce个数，设置参数后，自动合并后的文件大小平均，且不需要额外的任务做小文件合并，性能和耗时都有明显提升。
3. 手动设定map端、reduce端个数

### 思路2 ： 小文件合并

对小文件输出的时候进行合并 ,包括写入时处理和写入后处理

1. 设置map端、reduce端输出进行合并，设置合并文件的大小，当输出文件的平均大小小于该值时，启动一个独立的任务进行文件merge。
2. 小文件生成之后，单独启动任务进行归档合并，如hadoop archive，生成一个HAR文件去存储。或者编写手动合并小文件程序，去把已存在分区、分桶内的所有小文件combine到一个文件中。
3. 在写入时不会每次都生成一个小文件，而是通过找出低于设定阈值的现有小文件进行追加写来规避小文件。需要维护一套索引机制，具备可以动态分配记录到不同文件的能力。
4. 输出后小文件进行同步或已补聚簇，如hudi Clustering使得大数据进行流处理，摄取可以写入小文件以满足流处理的延迟要求，也可以在后台使用Clustering将这些小文件重写成较大的文件并减少文件数。



## 题目2

未做

## 题目3

未做
